{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50453df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809be50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5702d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758c46f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda'  if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dc5ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "train_dataset = datasets.ImageFolder(r'C:\\Users\\Lance\\Python class\\Untitled Folder\\selfie2anime', transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418b1fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images):\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(make_grid(images.detach(), nrow=22).permute(1, 2, 0))\n",
    "\n",
    "def show_batch(dl):\n",
    "    for images, _ in dl:\n",
    "        show_images(images)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3670db",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c9b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (3, 64, 64)\n",
    "image_dim = int(np.prod(image_shape))\n",
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5063656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        torch.nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "        torch.nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b02ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, 64 * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(64 * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64 * 8, 64 * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64 * 4, 64 * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64 * 2, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd96b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "generator.apply(weights_init)\n",
    "print(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560406f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(generator, (100,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c49e008",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 64 * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64 * 2, 64 * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64 * 4, 64 * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64 * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9712e858",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator().to(device)\n",
    "discriminator.apply(weights_init)\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5040dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(discriminator, (3,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0049e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_loss = nn.BCELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f5a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output, label):\n",
    "    gen_loss = adversarial_loss(fake_output, label)\n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1574caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(output, label):\n",
    "    disc_loss = adversarial_loss(output, label)\n",
    "    return disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1628a217",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(128, latent_dim, 1, 1, device=device)\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329ccba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0002 \n",
    "G_optimizer = optim.Adam(generator.parameters(), lr = learning_rate, betas=(0.5, 0.999))\n",
    "D_optimizer = optim.Adam(discriminator.parameters(), lr = learning_rate, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234bd730",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir t_weights\n",
    "!mkdir images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc4ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "D_loss_plot, G_loss_plot = [], []\n",
    "for epoch in range(1, num_epochs+1): \n",
    "\n",
    "    D_loss_list, G_loss_list = [], []\n",
    "   \n",
    "    for index, (real_images, _) in enumerate(train_loader):\n",
    "        D_optimizer.zero_grad()\n",
    "        real_images = real_images.to(device)\n",
    "      \n",
    "        real_target = Variable(torch.ones(real_images.size(0)).to(device))\n",
    "        fake_target = Variable(torch.zeros(real_images.size(0)).to(device))\n",
    "        \n",
    "        real_target = real_target.unsqueeze(1)\n",
    "        fake_target = fake_target.unsqueeze(1)\n",
    "\n",
    "        D_real_loss = discriminator_loss(discriminator(real_images), real_target)\n",
    "        D_real_loss.backward()\n",
    "    \n",
    "        noise_vector = torch.randn(real_images.size(0), latent_dim, 1, 1, device=device)  \n",
    "        noise_vector = noise_vector.to(device)\n",
    "    \n",
    "        generated_image = generator(noise_vector)\n",
    "        output = discriminator(generated_image.detach())\n",
    "        D_fake_loss = discriminator_loss(output,  fake_target)\n",
    "\n",
    "        D_fake_loss.backward()\n",
    "      \n",
    "        D_total_loss = D_real_loss + D_fake_loss\n",
    "        D_loss_list.append(D_total_loss)\n",
    "\n",
    "        D_optimizer.step()\n",
    "\n",
    "        \n",
    "        G_optimizer.zero_grad()\n",
    "        G_loss = generator_loss(discriminator(generated_image), real_target)\n",
    "        G_loss_list.append(G_loss)\n",
    "\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "\n",
    "\n",
    "    print('Epoch: [%d/%d]: D_loss: %.3f, G_loss: %.3f' % (\n",
    "            (epoch), num_epochs, torch.mean(torch.FloatTensor(D_loss_list)),\\\n",
    "             torch.mean(torch.FloatTensor(G_loss_list))))\n",
    "    \n",
    "    D_loss_plot.append(torch.mean(torch.FloatTensor(D_loss_list)))\n",
    "    G_loss_plot.append(torch.mean(torch.FloatTensor(G_loss_list)))\n",
    "    save_image(generated_image.data[:50], './images/sample_%d'%epoch + '.png', nrow=5, normalize=True)\n",
    "     \n",
    "    torch.save(generator.state_dict(), './t_weights/generator_epoch_%d.pth' % (epoch))\n",
    "    torch.save(discriminator.state_dict(), './t_weights/discriminator_epoch_%d.pth' % (epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b032936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImagePaths(path):\n",
    "    image_names = []\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            fullpath = os.path.join(dirname, filename)\n",
    "            image_names.append(fullpath)\n",
    "    return image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a9534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def display_multiple_img(images_paths, rows, cols):\n",
    "    figure, ax = plt.subplots(nrows=rows,ncols=cols,figsize=(500,100) )\n",
    "    for ind,image_path in enumerate(images_paths):\n",
    "        image=cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "        try:\n",
    "            ax.ravel()[ind].imshow(image)\n",
    "            ax.ravel()[ind].set_axis_off()\n",
    "        except:\n",
    "            continue;\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafe7a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_multiple_img(getImagePaths('./images'),num_epochs//2 , 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25c67ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
